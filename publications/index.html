<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Aakash KT</title> <meta name="author" content="Aakash KT"/> <meta name="description" content="Full publications list."/> <meta name="keywords" content="aakashkt, real-time-rendering, computer-graphics, ray-tracing, path-tracing"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://aakashkt.github.io/publications/"> <link rel="stylesheet" href="assets/css/image_comparison_style.css"> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script> <script src="assets/js/image_comparison.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://aakashkt.github.io//">Aakash KT</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h2 class="post-title" align="center">Publications</h2> <h6 class="post-title" align="center" style="color:dodgerblue"></h6> <h6 class="post-title" align="center"></h6> <br> <p class="post-description" align="center"><b></b></p> </header> <article> <div class="publications"> <h2 class="">2023</h2> <hr> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/ishaan_sigasia.jpg" style="width:100% ; height: auto"> </div> <div id="ishaan_sigasib" class="col-sm-10"> <div class="title"><h4>Combining Resampled Importance and Projected Solid Angle Samplings for Many Area Light Rendering</h4></div> <div class="author"> <a href="https://ishaanshah.github.io/" target="_blank" rel="noopener noreferrer">Ishaan Shah*</a>,  <b>Aakash KT*</b>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>ACM SIGGRAPH Asia 2023</b>, Technical Communications (Formerly Technical Briefs)</div> <div class="links"> <a href="https://drive.google.com/file/d/1Bkza6NHruo1VtIIenG5JYts_Q4CGTc-8/view?usp=sharing" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/ishaanshah/risltc" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://ishaanshah.github.io/risltc/" role="button" target="_blank" rel="noopener noreferrer">[Project Page]</a> <a href="/ris_projsa_genesis" role="button">[Genesis]</a> </div> <br> <div> <p>We identify the core issue for the high run-times of a naive combination of RIS and projected solid angle sampling. We then reformulate RIS for a better integration with projected solid angle sampling, achieving the state-of-the-art in many area light rendering.</p> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/sig_asia_doc.jpg" style="width:100% ; height: auto"> </div> <div id="kt_doctoral_consortium" class="col-sm-10"> <div class="title"><h4>Analytical &amp; Neural approaches to Physically Based Rendering</h4></div> <div class="author"> <b>Aakash KT</b> </div> <div class="periodical"> <b>ACM SIGGRAPH Asia 2023</b>, Doctoral Consortium</div> <div class="links"> <a href="https://drive.google.com/file/d/1CZOWZrA_w4ygUu60Wslu3EMCWkD3Nrkg/view?usp=sharing" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> </div> <br> <div> <p>Summary of my PhD thesis, including two extensions to LTCs and the extension of NRC for efficient hair rendering.</p> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/egsr2023.png" style="width:100% ; height: auto"> </div> <div id="10.1111:cgf.14895" class="col-sm-10"> <div class="title"><h4>Accelerating Hair Rendering by Learning High-Order Scattered Radiance</h4></div> <div class="author"> <b>Aakash KT</b>, <a href="https://scholar.google.es/citations?user=pXKBhbkAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Adrian Jarabo</a>, <a href="http://www.aliagabadal.com/" target="_blank" rel="noopener noreferrer">Carlos Aliaga</a>, <a href="https://mattchiangvfx.com/" target="_blank" rel="noopener noreferrer">Matt Jen-Yuan Chiang</a>, <a href="https://www.linkedin.com/in/olivier-maury-7abaa0" target="_blank" rel="noopener noreferrer">Olivier Maury</a>, <a href="https://www.linkedin.com/in/christophehery" target="_blank" rel="noopener noreferrer">Christophe Hery</a>, <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a>, and <a href="https://sites.google.com/view/gjnam" target="_blank" rel="noopener noreferrer">Giljoo Nam</a> </div> <div class="periodical"> <b>Eurographics Symposium on Rendering (EGSR) 2023</b>, Computer Graphics Forum (CGF) Vol. 42, No. 4</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="http://cvit.iiit.ac.in/images/ConferencePapers/2023/Hair_Path_Tracing_Acceleration.pdf" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/facebookresearch/HairMSNN" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="/hair_high_order.html" role="button">[Project Page]</a> <a href="/hair_high_order_genesis" role="button">[Genesis]</a> </div> <br> <div> <p>Efficiently and accurately rendering hair accounting for multiple scattering is a challenging open problem. We present a technique to infer the higher order scattering in hair in constant time within the path tracing framework, while achieving better computational efficiency.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1111:cgf.14895</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Accelerating Hair Rendering by Learning High-Order Scattered Radiance}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{KT, Aakash and Jarabo, Adrian and Aliaga, Carlos and Chiang, Matt Jen-Yuan and Maury, Olivier and Hery, Christophe and Narayanan, P. J. and Nam, Giljoo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association and John Wiley &amp; Sons Ltd.}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1467-8659}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/cgf.14895}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{Eurographics Symposium on Rendering (EGSR) 2023}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum (CGF) Vol. 42, No. 4}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/egsr2023.png}</span><span class="p">,</span>
  <span class="na">genesis</span> <span class="p">=</span> <span class="s">{/hair_high_order_genesis}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> </ol> <br> <h2 class="">2022</h2> <hr> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/icvgip_2022_dhawal.png" style="width:100% ; height: auto"> </div> <div id="dhawal2022prtsdf" class="col-sm-10"> <div class="title"><h4>Real-Time Rendering of Arbitrary Surface Geometries using Learnt Transfer</h4></div> <div class="author"> <a href="https://dhawal1939.github.io/" target="_blank" rel="noopener noreferrer">Sirikonda Dhawal</a>,  <b>Aakash KT</b>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>ICVGIP 2022</b>, Full Paper</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="https://iiitaphyd-my.sharepoint.com/:b:/g/personal/dhawal_sirikonda_research_iiit_ac_in/EUKOrBzrxrxFsOhmYFLArFcBtWBpY2nfx_CziCUC-JHneg?e=MrdxAJ" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://dhawal1939.github.io/projects/sh_rendering/#learnttransfer" role="button" target="_blank" rel="noopener noreferrer">[Project Page]</a> </div> <br> <div> <p>In this paper, we propose a compact transfer representation that is learnt directly on scene geometry points. Specifically, we train a small multi-layer perceptron (MLP) to predict the transfer at sampled surface points.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dhawal2022prtsdf</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dhawal, Sirikonda and KT, Aakash and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Rendering of Arbitrary Surface Geometries using Learnt Transfer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3571600.3571640}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{ICVGIP 2022 - (To appear in ACM Digital Library)}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{ICVGIP 2022}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Full Paper}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/icvgip_2022_dhawal.png}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/mlp_fit.png" style="width:100% ; height: auto"> </div> <div id="dhawal_learnt_prt" class="col-sm-10"> <div class="title"><h4>Learnt Transfer for Surface Geometries</h4></div> <div class="author"> <a href="https://dhawal1939.github.io/" target="_blank" rel="noopener noreferrer">Sirikonda Dhawal</a>,  <b>Aakash KT</b>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>High Performance Graphics 2022 (HPG)</b>, Poster</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="https://www.highperformancegraphics.org/posters22/HPG2022_Poster7_Learnt_Transfer_for_Surface_Geometries.pdf" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://dhawal1939.github.io/projects/sh_rendering/#learnttransfer" role="button" target="_blank" rel="noopener noreferrer">[Project Page]</a> </div> <br> <div> <p></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dhawal_learnt_prt</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dhawal, Sirikonda and KT, Aakash and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learnt Transfer for Surface Geometries}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{High Performance Graphics 2022 (HPG)}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Poster}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/mlp_fit.png}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/i3d2022.jpg" style="width:100% ; height: auto"> </div> <div id="10.1145/3522612" class="col-sm-10"> <div class="title"><h4>Bringing Linearly Transformed Cosines to Anisotropic GGX</h4></div> <div class="author"> <b>Aakash KT</b>, <a href="https://eheitzresearch.wordpress.com/" target="_blank" rel="noopener noreferrer">Eric Heitz</a>, <a href="https://onrendering.com/" target="_blank" rel="noopener noreferrer">Jonathan Dupuy</a>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) 2022</b>, PACM-CGIT, <b style="color: red;">Best Paper Award</b> </div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="https://arxiv.org/abs/2203.11904" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://drive.google.com/file/d/1UmRz1AEGkShMwdG6mJZnpIeC4mfa-hrn/view?usp=sharing" role="button" target="_blank" rel="noopener noreferrer">[Supp]</a> <a href="https://github.com/AakashKT/LTC-Anisotropic" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://www.youtube.com/watch?v=P-wRgPe8sDs&amp;t=8500s&amp;ab_channel=I3DSymposium" role="button" target="_blank" rel="noopener noreferrer">[Slides]</a> <a href="/ltc_anisotropic.html" role="button">[Project Page]</a> <a href="/aniso_ltc_genesis" role="button">[Genesis]</a> </div> <br> <div> <p>We present an extension to LTCs for anisotropic GGX, in the context of real-time analytic area light shading. Our approach robustly fits LTC matrices to anisotropic GGX and ensures artefact free rendering. The end result is a 8<sup>4</sup> LUT parameterized by the elevation and azimuth of view vector and the roughness in x and y directions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1145/3522612</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{KT, Aakash and Heitz, Eric and Dupuy, Jonathan and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bringing Linearly Transformed Cosines to Anisotropic GGX}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{May 2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3522612}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3522612}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Comput. Graph. Interact. Tech.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{area lighting, BRDF, LTC, real-time rendering}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) 2022}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{PACM-CGIT}</span><span class="p">,</span>
  <span class="na">best_paper</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/i3d2022.jpg}</span><span class="p">,</span>
  <span class="na">genesis</span> <span class="p">=</span> <span class="s">{/aniso_ltc_genesis}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/prt_transfer_tex.jpg" style="width:100% ; height: auto"> </div> <div id="dhawal2022prtt" class="col-sm-10"> <div class="title"><h4>PRTT: Precomputed Radiance Transfer Textures</h4></div> <div class="author"> <a href="https://dhawal1939.github.io/" target="_blank" rel="noopener noreferrer">Sirikonda Dhawal</a>,  <b>Aakash KT</b>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>Eurographics (EG) 2022</b>, Poster</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="https://arxiv.org/abs/2203.12399" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://diglib.eg.org/handle/10.2312/egp20221012" role="button" target="_blank" rel="noopener noreferrer">[Poster]</a> </div> <br> <div> <p>We analyze and extend PRT to use textures for storing transfer, instead of at vertices of a mesh. We demonstrate better rendering quality for the same mesh resolution for glossy reflection and inter-reflections. We also analyze the run-time, memory requirements and demonstrate benefits of using transfer textures.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">dhawal2022prtt</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PRTT: Precomputed Radiance Transfer Textures}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dhawal, Sirikonda and KT, Aakash and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2203.12399}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{Eurographics (EG) 2022}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Poster}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/prt_transfer_tex.jpg}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> </ol> <br> <h2 class="">2021</h2> <hr> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/egsr2021.png" style="width:100% ; height: auto"> </div> <div id=".20211295" class="col-sm-10"> <div class="title"><h4>Fast Analytic Soft Shadows from Area Lights</h4></div> <div class="author"> <b>Aakash KT</b>, <a href="https://researchweb.iiit.ac.in/~parikshit.sakurikar/" target="_blank" rel="noopener noreferrer">Parikshit Sakurikar</a>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>Eurographics Symposium on Rendering (EGSR) 2021</b>, DL-only track</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="http://cvit.iiit.ac.in/images/ConferencePapers/2021/analytic_ss.pdf" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/AakashKT/analytic_ss_cpu" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://youtu.be/iETDEkcRI8M?t=10982" role="button" target="_blank" rel="noopener noreferrer">[Slides]</a> <a href="/fast_ss_genesis" role="button">[Genesis]</a> </div> <br> <div> <p>We present an analytical solution for soft shadows from area lights, which naturally produces noise-free renderings as compared to equivalent stochastic methods. A structured approach to analytically compute soft shadows from spherical projections of lights and occluders with any 3D shape and efficiently for convex 3D shapes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">.20211295</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eurographics Symposium on Rendering - DL-only Track}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Bousseau, Adrien and McGuire, Morgan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Fast Analytic Soft Shadows from Area Lights}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{KT, Aakash and Sakurikar, Parikshit and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1727-3463}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-157-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/sr.20211295}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{Eurographics Symposium on Rendering (EGSR) 2021}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{DL-only track}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/egsr2021.png}</span><span class="p">,</span>
  <span class="na">genesis</span> <span class="p">=</span> <span class="s">{/fast_ss_genesis}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/icvgip.jpg" style="width:100% ; height: auto"> </div> <div id="10.1145/3490035.3490299" class="col-sm-10"> <div class="title"><h4>Neural View Synthesis with Appearance Editing from Unstructured Images</h4></div> <div class="author"> <a href="https://darthgera123.github.io/" target="_blank" rel="noopener noreferrer">Pulkit Gera</a>,  <b>Aakash KT</b>, <a href="https://dhawal1939.github.io/" target="_blank" rel="noopener noreferrer">Sirikonda Dhawal</a>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>ICVGIP 2021</b>, Full Paper</div> <div class="links"> <a class="bibtex" role="button">[BibTex]</a> <a href="https://dl.acm.org/doi/abs/10.1145/3490035.3490299" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/darthgera123/Appearance-Editing" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="https://darthgera123.github.io/appearance-editing/" role="button" target="_blank" rel="noopener noreferrer">[Project Page]</a> </div> <br> <div> <p>We present a neural rendering framework for simultaneous view synthesis and appearance editing of a scene with known environmental illumination captured using a mobile camera. Our approach explicitly disentangles the appearance and learns a lighting representation that is independent of it. We show results of editing the appearance of real scenes in interesting and non-trivial ways.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3490035.3490299</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gera, Pulkit and KT, Aakash and Dhawal, Sirikonda and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural View Synthesis with Appearance Editing from Unstructured Images}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450375962}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3490035.3490299}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3490035.3490299}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Twelfth Indian Conference on Computer Vision, Graphics and Image Processing}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{40}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{text tagging, LATEX, ACM proceedings}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Jodhpur, India}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ICVGIP '21}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{ICVGIP 2021}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Full Paper}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/icvgip.jpg}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> </ol> <br> <h2 class="">2019</h2> <hr> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/iiit_logo.png" style="width:100% ; height: auto"> </div> <div id="aakash_kt_ms_thesis" class="col-sm-10"> <div class="title"><h4>Exploring Data Driven Graphics for Interactivity</h4></div> <div class="author"> <b>Aakash KT</b>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>IIIT-H</b>, Master’s Thesis</div> <div class="links"> <a href="https://web2py.iiit.ac.in/research_centres/publications/view_publication/mastersthesis/1078" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> </div> <br> <div> <p></p> </div> </div> </div> <br> </li> <li> <div class="row"> <div class="col-sm-2"> <img src="/assets/img/neural-material-vis.png" style="width:100% ; height: auto"> </div> <div id="KT:2019:FNR:3355088.3365160" class="col-sm-10"> <div class="title"><h4>A Flexible Neural Renderer for Material Visualization</h4></div> <div class="author"> <b>Aakash KT</b>, <a href="https://researchweb.iiit.ac.in/~parikshit.sakurikar/" target="_blank" rel="noopener noreferrer">Parikshit Sakurikar</a>, <a href="https://sophont01.github.io/" target="_blank" rel="noopener noreferrer">Saurabh Saini</a>, and <a href="https://scholar.google.co.in/citations?user=3HKjt_IAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">P. J. Narayanan</a> </div> <div class="periodical"> <b>ACM SIGGRAPH Asia 2019</b>, Technical Briefs</div> <div class="links"> <a href="https://arxiv.org/abs/1908.09530" role="button" target="_blank" rel="noopener noreferrer">[arXiv]</a> <a class="bibtex" role="button">[BibTex]</a> <a href="https://dl.acm.org/doi/10.1145/3355088.3365160" role="button" target="_blank" rel="noopener noreferrer">[PDF]</a> <a href="https://github.com/AakashKT/NeuralMaterialVisualization" role="button" target="_blank" rel="noopener noreferrer">[Code]</a> <a href="/flexible_nr" role="button">[Project Page]</a> <a href="/flexible_nr_genesis" role="button">[Genesis]</a> </div> <br> <div> <p>Photo realism in computer generated imagery is crucially dependent on how well an artist is able to recreate real-world materials in the scene. We propose a convolutional neural network based workflow which generates high-quality ray traced material visualizations on a shaderball, in real-time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KT:2019:FNR:3355088.3365160</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{KT, Aakash and Sakurikar, Parikshit and Saini, Saurabh and Narayanan, P. J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Flexible Neural Renderer for Material Visualization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{SIGGRAPH Asia 2019 Technical Briefs}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{SA '19}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-4503-6945-9}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Brisbane, QLD, Australia}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{83--86}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://doi.acm.org/10.1145/3355088.3365160}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3355088.3365160}</span><span class="p">,</span>
  <span class="na">acmid</span> <span class="p">=</span> <span class="s">{3365160}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Deep Learning, Global Illumination, Neural Rendering, Ray Tracing}</span><span class="p">,</span>
  <span class="na">conference_display_name</span> <span class="p">=</span> <span class="s">{ACM SIGGRAPH Asia 2019}</span><span class="p">,</span>
  <span class="na">track_display_name</span> <span class="p">=</span> <span class="s">{Technical Briefs}</span><span class="p">,</span>
  <span class="na">icon</span> <span class="p">=</span> <span class="s">{/assets/img/neural-material-vis.png}</span><span class="p">,</span>
  <span class="na">genesis</span> <span class="p">=</span> <span class="s">{/flexible_nr_genesis}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <br> </li> </ol> <br> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Aakash KT. Aakash KT Last updated: November 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>